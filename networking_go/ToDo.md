基于"尽量少用封装、理解底层"的目标，你需要**分阶段实现**，从"能让两个程序说上话"开始，逐步进化到"理解 HTTP 本质"。以下是你要从零实现的**能力清单**：

## 第一阶段：TCP 服务器（建立连接）

**核心目标**：让客户端能连上来，说一句"你好"，服务器回一句"收到"，然后断开。

你要亲手实现：

1. **地址绑定系统**
   - 把程序绑定到本机的一个端口（如 `:8080`）
   - 理解**监听队列**（backlog）——内核帮你暂存来不及处理的连接请求

2. **连接的生命周期管理**
   - **Accept 循环**： forever 循环等待敲门的人（这是阻塞的）
   - **_conn 分离_**：接受连接后，原来的"门卫"继续站岗，新开的"窗口"（goroutine）专门服务这个客人
   - **优雅关闭**：客户端走了（EOF）或网络断了，你要能感知并清理资源（defer close）

3. **原始字节流通信**
   - 用**固定大小的 buffer**（如 1024 字节）从连接中"舀"数据（像从水管里舀水）
   - 处理**粘包问题**：TCP 是流，你可能一次读到"HelloWorld"（客户端发了两次），要学会按边界分割（先实现简单的 `\n` 分隔符协议）

**此阶段禁用的便利**：不要用 `bufio.Reader`（先用裸 `conn.Read` 感受什么叫"不知道有多少数据"）。

---

## 第二阶段：TCP 服务器的并发与资源控制

**核心目标**：能同时处理 100 个连接，且不会因为客户端捣乱（如只连不发数据）而瘫痪。

你要实现：

1. **并发模型**
   - 每连接一个 goroutine（这是 Go 的标准做法，但你要意识到每个 goroutine 占 2KB 栈内存）
   - **WaitGroup 或 ErrGroup**：主线程能知道所有子 goroutine 何时全部结束（优雅重启的基础）

2. **超时控制**
   - **读超时**：设置 `SetReadDeadline`，防止恶意客户端挂着连接不发送数据（占着茅坑不拉屎）
   - **写超时**：防止对端接收极慢导致你的发送 buffer 无限积压

3. **连接数限制**（可选但重要）
   - 用 `channel` 当信号量（如 `make(chan struct{}, 100)`），超过 100 个连接直接拒绝（保护内存）

**此阶段的概念重点**：理解 goroutine 泄漏（忘记 close conn 会导致 fd 和内存永远占着）。

---

## 第三阶段：为 HTTP 打基础——协议解析

**核心目标**：在 TCP 上实现一个"类 HTTP"的文本协议，理解 HTTP 只是 TCP 上的一种数据格式。

你要实现：

1. **请求解析器（Request Parser）**
   - 从字节流中识别**请求行**（`METHOD PATH VERSION\r\n`）
   - 解析**Header 段**（`Key: Value\r\n` 直到遇到空行 `\r\n\r\n`）
   - **长度判断**：如果 Header 里有 `Content-Length`，继续读取对应字节数作为 Body；如果没有，说明是 GET 请求，没有 Body

2. **响应构造器（Response Builder）**
   - 手写字符串拼接：`"HTTP/1.1 200 OK\r\nContent-Length: 5\r\n\r\nHello"`
   - 理解 `\r\n`（CRLF）是 HTTP 的命脉，少一个字符浏览器就挂

3. **错误处理**
   - 如果解析失败（如请求行格式不对），返回 `400 Bad Request` 并关闭连接

**此阶段的关键**：HTTP 是**无状态**的，每个请求-响应后连接可能关闭（HTTP/1.0）或保持（HTTP/1.1 keep-alive），你要实现 `Connection: close` 的逻辑。

---

## 第四阶段：HTTP 服务器（TCP + 协议）

**核心目标**：用浏览器能访问，且返回正确的 HTML。

基于第三阶段的解析器，你现在要实现：

1. **路由系统（Router）**
   - 最简单的 `map[string]func(Request) Response`
   - 能区分 `GET /` 和 `GET /about`
   - 处理 `404 Not Found`

2. **静态文件服务**（HTTP 的核心场景）
   - 根据 URL 路径映射到本地文件系统（如 `./static/index.html`）
   - **MIME 类型判断**：根据文件后缀（`.html`、`.css`、`.jpg`）返回正确的 `Content-Type`（浏览器靠这个决定怎么渲染）
   - **文件读取**：用 `os.Open` 读文件，通过 `io.Copy` 或手写循环发送到 `conn`（这里可以感受零拷贝优化的必要性）

3. **并发安全**
   - 如果多个请求同时读写同一个文件，是否需要加锁？（通常是读多写少，可以不加，但要知道风险）

---

## 第五阶段：HTTP 进阶特性（理解现代 Web）

**核心目标**：支持更真实的 Web 场景，理解 HTTP 的复杂性。

你要实现：

1. **Connection: keep-alive 支持**
   - 在一个 TCP 连接上处理**多个** HTTP 请求（"长连接"）
   - 这要求你的解析器能从流中连续读出多个请求，并正确分割（不能读过头把下一个请求的数据也吃了）

2. **Chunked Transfer Encoding**（分块传输）
   - 如果服务器不知道文件总大小（如动态生成），不能用 `Content-Length`，要学会 `Transfer-Encoding: chunked` 格式（每个块先写长度，再写数据，最后写 0 表示结束）

3. **简单的中间件机制**
   - 实现一个洋葱模型：Logging（记录请求时间）→ Auth（检查Header）→ Handler（业务逻辑）

---

## 给你的学习路径建议

**TCP 阶段任务清单**：
1. [ ] 绑定端口，打印"Server started on :8080"
2. [ ] 用 `telnet localhost 8080` 连接，你输入什么服务器回显什么（Echo Server）
3. [ ] 实现"长度前缀协议"：客户端先发 4 字节表示后续数据长度，服务器按长度读取（理解二进制协议）
4. [ ] 加上超时控制，用 `time.Sleep` 模拟慢客户端，测试服务器会不会被拖垮

**HTTP 阶段任务清单**：
1. [ ] 用浏览器访问，返回 `<h1>Hello World</h1>`（看浏览器是否正常渲染，不是下载文件）
2. [ ] 实现 `curl -v` 能看到的完整 Header（包括 `Date` 服务器时间）
3. [ ] 支持访问 `http://localhost:8080/README.md` 返回当前目录的文件内容（简易文件服务器）
4. [ ] 测试 `keep-alive`：用 `curl -v --http1.1 http://localhost:8080/ http://localhost:8080/about` 看是否复用了同一个 TCP 连接（通过 Wireshark 或 `-v` 输出的连接信息验证）

**关键提醒**：在开始写 HTTP 之前，确保你的 TCP 服务器能正确处理**"对端突然断开"**（拔网线模拟）和**"对端发送大量数据"**（用 `cat /dev/zero | nc localhost 8080` 测试），这是区分玩具和生产代码的分水岭。

准备好先从哪个阶段开始？